---
title: ICCV 2017 扫读总结
mathjax: true
categories:
  - - 技术
    - 学习
tags:
  - 论文
description: 扫读 ICCV 2017 论文集中感兴趣的论文，将根据 略读 - 细读 - 精读 的方式快速过一遍
abbrlink: c254b0
date: 2023-03-06 22:24:59
---

本次扫读从 ICCV 2017 论文集 600 篇中根据论文名称寻找了感兴趣的 50 篇，将根据 略读 - 细读 - 精读 的方式将这 50 篇论文快速过一遍

> 因时间关系最后只读了其中的 18 篇

## 阅读方式

### 略读

所有论文都先过一遍 Abstract 、Introduction 、Conclusion ，简要了解该论文的主要贡献

若该论文的应用场景、研究方向不合预期，则立刻略过

### 细读

将全文过一遍，但不细究其中的技术，主要把流程捋顺

### 精读

对于十分契合研究方向论文，将会仔细学习其中的算法流程和思路

## 18 篇论文

### 3D Graph Neural Networks for RGBD Semantic Segmentation[^1]

此前利用 RGB 图像和深度图像进行语义分割的方法是分别对这两个图像输入进 CNN 神经网络，这样做的计算成本和内存成本很大

该论文提出了一种 3D 图神经网络（ 3DGNN ），在点云上构建 k 最临近图，分别输入 RGB 图像、深度图像和点云，输出 RGB 图像的语义分类结果

考虑到适用场景不同以及 GNN 的复杂性，略过该论文

[^1]: Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, and Raquel Urtasun. 2017. 3D Graph Neural Networks for RGBD Semantic Segmentation. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 5209–5218. DOI:<https://doi.org/10.1109/ICCV.2017.556>

### 2D-Driven 3D Object Detection in RGB-D Images[^2]

在 3D 目标检测中，一般使用 3D 边界框标注目标，但是 3D 标注框的计算成本较大且难以利用到点云中的局部特性

该论文提出了利用 RGB 图像和深度图像的 2D 目标检测驱动 3D 目标检测，先进行二维图像的目标检测，然后利用得到的 2D 边界框在 3D 点云上重新配准的到 3D 边界框

考虑到适用场景不同，略过该论文

[^2]: Jean Lahoud and Bernard Ghanem. 2017. 2D-Driven 3D Object Detection in RGB-D Images. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 4632–4640. DOI:<https://doi.org/10.1109/ICCV.2017.495>

### 3D Surface Detail Enhancement from A Single Normal Map[^3]

现有的三维重建算法重建的表面质量受到输入图像质量的影响，如何利用现有质量的图像重建更优质表面是需要解决的问题

该论文提出了一种不需要训练数据集、不依赖硬件的三维重建方式，提高了表面的细腻度

该论文不是基于深度学习，略过

[^3]: Wuyuan Xie, Miaohui Wang, Xianbiao Qi, and Lei Zhang. 2017. 3D Surface Detail Enhancement from a Single Normal Map. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 2344–2352. DOI:<https://doi.org/10.1109/ICCV.2017.255>

### 3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks[^4]

该论文提出了一种基于 RNN 输入深度图像、能够生成三维模型的 3D-PRNN 模型和一种基于高斯场和能量最小化的点云拟合基元的有效方法，能够有效应用于三维重建

考虑到应该不会使用深度图像，略过

[^4]: Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan, and Derek Hoiem. 2017. 3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 900–909. DOI:<https://doi.org/10.1109/ICCV.2017.103>

### 3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds[^5]

该论文提出了一种自动解析大规模三维点云的 3DCNN-DQN-RNN 模型，利用 3DCNN 提取点云的特征，利用 RNN 融合 3DCNN 得到的各种特征，利用 DQN 进行类滑动窗口的操作，实现定位、检测、分类的集成

略感兴趣，可以后期再看看

DQN 是未见过的一类神经网络架构，后面也可以再留意

[^5]:  Fangyu Liu, Shuaipeng Li, Liqiang Zhang, Chenghu Zhou, Rongtian Ye, Yuebin Wang, and Jiwen Lu. 2017. 3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-Scale 3D Point Clouds. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 5679–5688. DOI:<https://doi.org/10.1109/ICCV.2017.605>

### A Read-Write Memory Network for Movie Story Understanding*[^6]

论文提出了一种基于 ResNet 和 Word2Vec 网络和 CNN 结构的电影故事理解模型，输入画面和台词，可以很好地回答针对故事的提问

只是对这方面略感兴趣，快速略过

[^6]: Seil Na, Sangho Lee, Jisung Kim, and Gunhee Kim. 2017. A Read-Write Memory Network for Movie Story Understanding. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 677–685. DOI:<https://doi.org/10.1109/ICCV.2017.80>

### Adversarial Examples for Semantic Segmentation and Object Detection*[^7]

对对抗样本感兴趣，于是看到这篇论文的时候挑出来了

为了应对输入中的微小扰动带来的论文提出了一种密集对抗生成的新算法

只是看摘要、总结和引言看不出什么，快速略过

[^7]:  Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, and Alan Yuille. 2017. Adversarial Examples for Semantic Segmentation and Object Detection. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 1378–1387. DOI:<https://doi.org/10.1109/ICCV.2017.153>

### An Empirical Study of Language CNN for Image Captioning*[^8]

论文提出的网络是非典型的神经网络，使用了图像和文字作为输入

论文提出的模型首先将图片输入进 CNN 里面得到特征，然后再将特征作为 RNN 的基础状态，和文字一起进行 RNN ，最终实现 Image To Text

快速略过

[^8]: Jiuxiang Gu, Gang Wang, Jianfei Cai, and Tsuhan Chen. 2017. An Empirical Study of Language CNN for Image Captioning. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 1231–1240. DOI:<https://doi.org/10.1109/ICCV.2017.138>

### BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth[^9]

论文提出了一种基于二维图像进行物体的三维姿势检测的方法，实现了在图像上预测物体的三维边界框

但是论文中没有提出具体的模型，感觉不是很可靠，或者说因此觉得他不希望被复现

可以暂存

[^9]: Mahdi Rad and Vincent Lepetit. 2017. BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 3848–3856. DOI:<https://doi.org/10.1109/ICCV.2017.413>

### Channel Pruning for Accelerating Very Deep Neural Networks[^10]

论文提出了一种修剪卷积神经网络通道的方法，通过减少卷积神经网络中的通道数加速网络计算并将因此带来的误差减少到一定程度，且该方法具有很强的拓展性，可以在 VGG 、 ResNet 上使用该方法

可以暂存

[^10]: Yihui He, Xiangyu Zhang, and Jian Sun. 2017. Channel Pruning for Accelerating Very Deep Neural Networks. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 1398–1406. DOI:<https://doi.org/10.1109/ICCV.2017.155>

### Colored Point Cloud Registration Revisited[^11]

论文提出了一种针对 RGB-D 图像和 XYZRGB 点云结合的点云配准方法，效果优于基于机器学习的 ICP 配准和 FGR 配准方法

但是看起来好像不是基于深度学习，且需要用到深度图像

可以留意有没有作者公布的代码实现

[^11]: Jaesik Park, Qian-Yi Zhou, and Vladlen Koltun. 2017. Colored Point Cloud Registration Revisited. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 143–152. DOI:<https://doi.org/10.1109/ICCV.2017.25>

### DeepContext: Context-Encoding Neural Pathways for 3D Holistic Scene Understanding[^12]

论文提出了一种能够学习场景信息的三维卷积神经网络，通过对齐数据集学习到的基本场景模板和卷积神经网络，实现场景中物体的实例分割

可以暂存，但是如果应用在植物上的话，可能很难总结出不同的模板

[^12]: Yinda Zhang, Mingru Bai, Pushmeet Kohli, Shahram Izadi, and Jianxiong Xiao. 2017. DeepContext: Context-Encoding Neural Pathways for 3D Holistic Scene Understanding. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 1201–1210. DOI:<https://doi.org/10.1109/ICCV.2017.135>

### Directionally Convolutional Networks for 3D Shape Segmentation[^13]

论文提出了一种基于 Mesh 网格数据集的定向卷积神经网络 DCN 和普通神经网络结合的双流分割网络

双流指的是，同一输入分别送入不同网络中学习到不同的特征后融合在一起，本质上还是一种将多种方法结合在一起的作弊行为，虽然很好用

由于该网络是针对 Mesh 网格的，快速略过

[^13]: Haotian Xu, Ming Dong, and Zichun Zhong. 2017. Directionally Convolutional Networks for 3D Shape Segmentation. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 2717–2726. DOI:<https://doi.org/10.1109/ICCV.2017.294>

### Editable Parametric Dense Foliage from 3D Capture[^14]

论文提出了一种基于 RGB-D 图像的分割单个叶片的算法和利用 B ́ezier patches 模拟叶片表面进行重建叶片点云的方法

虽然很切合植物点云方向，但是由于该算法并不是基于深度学习且使用 C++ 实现，快速略过

[^14]: Paul Beardsley and Gaurav Chaurasia. 2017. Editable Parametric Dense Foliage from 3D Capture. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 5315–5324. DOI:<https://doi.org/10.1109/ICCV.2017.567>

### Efficient Global 2D-3D Matching for Camera Localization in a Large-Scale 3D Map[^15]

论文提出了一种基于 3D 点云的马尔可夫网络，实现了在大型 3D 点云中进行检索特定场景。

由于本文研究场景是在大型场景的 3D 点云与当前研究方向不太符合，略过

[^15]: Liu Liu, Hongdong Li, and Yuchao Dai. 2017. Efficient Global 2D-3D Matching for Camera Localization in a Large-Scale 3D Map. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 2391–2400. DOI:<https://doi.org/10.1109/ICCV.2017.260>

### Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules[^16]

论文提出了一种基于带有 RSTTM 的 3DCNN 模型，用于实现手势识别。此处的 3D 是指二维图像加上时间维度，即时序图像。

以为本文的 3D 是指三维立体物体，略过

[^16]: Congqi Cao, Yifan Zhang, Yi Wu, Hanqing Lu, and Jian Cheng. 2017. Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 3783–3791. DOI:<https://doi.org/10.1109/ICCV.2017.406>

### Embedding 3D Geometric Features for Rigid Object Part Segmentation[^17]

论文提出了一种基于 FCN 框架的双流 CNN 网络模型，其中一个名为 AppNet 的流可以从输入图像中提取 2D 外观，另一个名为 GeoNet 的流能够提取 3D 集合特征，将双流输出的特征结合起来实现对图像中物体的零件分割。由于 GeoNet 流的输入为二维图像，输出为 3D 集合特征，因此需要利用名为 VolNet 的基于 2D-CNN 的网络从 3D 体素中提取 3D 集合特征，并以此训练 GeoNet

该论文主要是利用图像和体素，与研究方向不符，略过

[^17]: Yafei Song, Xiaowu Chen, Jia Li, and Qinping Zhao. 2017. Embedding 3D Geometric Features for Rigid Object Part Segmentation. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 580–588. DOI:<https://doi.org/10.1109/ICCV.2017.70>

### End-to-End Learning of Geometry and Context for Deep Stereo Regression[^18]

论文提出了一种基于 2D-CNN 和 3D-CNN 的实现双目摄像机图像生成视差图像的卷积神经网络

该论文方向不属于三维重建，与研究方向不符，略过

[^18]: Alex Kendall, Hayk Martirosyan, Saumitro Dasgupta, Peter Henry, Ryan Kennedy, Abraham Bachrach, and Adam Bry. 2017. End-to-End Learning of Geometry and Context for Deep Stereo Regression. In 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, 66–75. DOI:<https://doi.org/10.1109/ICCV.2017.17>
